\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{fullpage}
\usepackage{hyperref}

\newtheorem{rg}{Reguła}
\newtheorem{twr}{Twierdzenie}

\title{Proste algorytmy klasyfikacji tekstu \\ Założenia wstępne projektu}
\author{Marcin Kaczyński \and Krystian Lieber}

\begin{document}

\maketitle

\section{Opis zadania} 

W ramach zadania - ''Proste algorytmy klasyfikacji tekstu (TF-IDF, naiwny klasyfikator Bayesowski, kNN). Porównania ze standardowymi algorytmami klasyfikacji dostępnymi w R.'' zajmiemy się implementacją 3 wymienionych klasyfikatorów które zostaną dostosowane i wykorzystane w zagadnieniu rozpoznawania reklam i niechcianych wiadomości SMS.\\

Do nauki i oceny klasyfikatorów zostanie wykorzystany zbiór \textit{SMS Spam Collection}\footnote{http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection} z repozytorium UCI. Opis tego zbioru znajduje się w kolejnych sekcjach niniejszego dokumentu.

\section{Algorytmy}

Załóżmy, że mamy dany zbiór uczący podzielony na klasy $C_i, i = 1, 2, \dots, m$. W zadaniu $i=2$. 

\subsection{Algorytm \textit{k-NN}}

W algorytmie klasyfikacji \textit{k-NN} dla klasyfikowanego przykładu $x$ szukamy $k$ (wartość z góry ustalona) próbek które leżą najbliżej $x$ w sensie ustalonej miary a następnie na podstawie głosowania wśród wybranych sąsiadów określamy do której klasy $C_i$ należy $x$.\\

W zadaniu do znalezienia najbliższych sąsiadów zostanie wykorzystana \textit{miara kosinusowa}.

\begin{center}
$sim(v_1, v_2) = \frac{v_1*v_2}{|v_1||v_2|}$
\end{center}

oraz miara \textit{TF-IDF} (opisana w kolejnych sekcjach).\\

Aby móc porównywać słowa wg wspomnianych miar, należy je przedstawić w postaci wektorowej. Podstawowa idea reprezentacji wektorowej sprowadza się do tego, że wiadomość jest reprezentowana w postaci wektora częstości występowania słów. Zbiór wszystkich wiadomości można przedstawić w postaci macierzy, o nazwie \textit{Term Frequency Matrix}, której element $[w_i, s_i]$ reprezentuje liczbę wystąpień słowa $s_i$ w wiadomości $w_i$. Dowolna wiadomość $w_i$ jest reprezentowana w postaci wektora częstości występowania słów kluczowych.

\subsection{Algorytm \textit{TF-IDF}}

\subsection{Naiwny klasyfikator Bayesa}
 
\begin{rg}[Bayes]
Próbkę $X$ klasyfikujemy jako pochodzącą z tej klasy $C_i$, dla której wartość $P(C_i|X), i = 1, 2, \dots, m$, jest największa.
\end{rg}
 
Problem sprowadza się do wyznaczenia prawdopodobieństw $P(C_i|X)$.
W ogólności aby wyznaczyć te prawdopodobieństwa, należy skorzystać z~następującego twierdzenia:

\begin{twr}[Bayes]
$P(C|X) = \frac{P(X|C)*P(C)}{P(X)}$
\end{twr}
 
gdzie:

\begin{itemize}
\item \textbf{$P(C)$} jest prawdopodobieństwem \textit{a priori} wystąpienia
klasy $C$,
\item \textbf{$P(X|C)$} oznacza prawdopodobieństwo \textit{a posteriori}, że
$X$ należy do klasy $C$,
\item \textbf{$P(X)$} oznacza prawdopodobieństwo \textit{a priori} wystąpienia przykładu $X$.
\end{itemize} 
 
Przy założeniu o niezależności atrybutów, prawdopodobieństwo $P(X|C_i)$ możemy wyznaczyć z formuły $P(X|C_i) = \prod\limits_{j=1}^n P(x_j|C_i)$, gdzie wartości prawdopodobieństw iloczynu estymujemy
w zależności od przyjętej metody.\\

Warto zaznaczyć, że w przypadku dokumentów tekstowych nie jest spełnione założenie o warunkowej niezależności wartości atrybutów, jednak w praktyce nie obniża to skuteczności klasyfikatora. W zadaniu klasyfikowania wiadomości atrybutami są kolejne słowa w wiadomości.\\

Przyjmujemy założenie, że prawdopodobieństwo wystąpienia słowa w tekście jest niezależne od jego pozycji. Dzięki temu założeniu znacząco maleje liczba estymat prawdopodobieństw które należy wyznaczyć podczas uczenia.\\

Do wyznaczenia wspomnianych estymat $P(x_j|C_i)$ wykorzystujemy następujący wzór:

\begin{center}
$\frac{n_k + 1}{n + |D|}$
\end{center}

gdzie $n$ - całkowita liczba słów w wiadomościach uczących które należą do klasy $C_i$, $n_k$ - liczba wystąpnień słow $x_j$ w tekstach z klasy $C_i$, a |D| - liczba rozróżnialnych słów występujących we wszystkich tekstach uczących.

\section{Plan eksperymentów}

\subsection{Pytania, na które będzie poszukiwana odpowiedź}

Celem zadania jest odpowiedzenie na pytanie, czy przekazana wiadomość SMS jest porządaną, zwykłą wiadomością, czy zawiera nieporządane treści lub reklamy.

\subsection{Charakterystyka zbioru danych}

Wybrany zbiór danych (\textit{SMS Spam Collection}) jest zbiorem etykietowanych wiadomości które zostały zebrane na potrzeby badania spamu wysyłanego SMS'ami. Korpus składa się z $4827$ zwykłych wiadomości oraz z $747$ wiadomości zawierających spam. Cała kolekcja wiadomości jest umieszczona w jednym pliku, w którym każda linijka składa się z etykiety wiadomości którą poprzedza oraz z wiadomości w oryginalnej postaci. Poniżej kilka przykładów:

\begin{itemize}
\item ham What you doing?how are you? 
\item ham dun say so early hor... U c already then say... 
\item ham MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H* 
\item spam FreeMsg: Txt: CALL to No: 86888 \& claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop 
\item spam Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B 
\item spam URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU 
\end{itemize}

\textbf{TODO} tutaj dodać jeszcze opis jakiegoś preprocessingu tych wiadomości

\subsection{Parametry algorytmów}

Parametry algorytmów, których wpływ na wyniki będzie badany.

\subsection{Sposób oceny jakości modeli}

W przypadku klasyfikacji narzuca sie prosty sposób oceny jakości modeli, taki, że dzielimy próbki na 2 podzbiory - zbiór uczący i zbiór testowy. Aby ocenić model przeprowadzamy uczenie klasyfikatora na próbkach pochodzących ze zbioru uczącego, a następnie sprawdzamy jaką jakość klasyfikacji uzyskujemy dla próbek ze zbioru testowego.\\

W naszym przypadku będziemy mierzyć jakość modeli na podstawie 2 wskaźników. Będziemy określali jakość klasyfikacji zwykłych wiadomości (a więc iloraz poprawnie sklasyfikowanych zwykłych wiadomości do wszystkich zwykłych wiadomości) oraz jakość klasyfikacji spamu (analogicznie iloraz poprawnie klasyfikowanych niechcianych wiadomości do ich łącznej liczby).\\

\section{Kwestie otwarte}

Ponieważ wykorzystywany korpus zawiera istotnie mniej spamu niż zwykłych wiadomości, aby zwiększyć jakość klasyfikacji i samą jakość oceny modelu tych drugich wiadomości skorzystamy z techniki nazywanej \textit{leave one out} lub \textit{jack knife}. Technika zakłada wielokrotne testowanie modelu przy takim podziale całego
zbioru próbek, że w zbiorze uczącym znajduje się $(n-1)$ próbek, a w zbiorze testowym 1 próbka. W naszym przypadku zmodyfikujemy tę technikę, tak żeby zbiór testowy składał się z pewnej liczby $k$ zwykłych wiadomości i 1 wiadomości zawierającej spam, a zbiór uczący ze wszystkich pozostałych próbek. Jeżeli uczenie klasyfikatorów okaże się czasochłonne, prawdopodobnie zrezygnujemy z tej części.\\

Otwartą kwestię stanowi dodatkowo zbiór \textit{stopwords} czyli słów które nie mają znaczenia dla klasyfikacji - te słowa mogą zostać usunięte z tekstów. Dodatkowo w przypadku wiadomości SMS warto zastanowić się nad pojawiajacymi się w wiadomościach skrótami (być może skróty zostaną włączone do listy \textit{stopwords} lub rozwinięte do pełnych słów).

\end{document}
