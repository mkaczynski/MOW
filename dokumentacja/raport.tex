\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{fullpage}
\usepackage{hyperref}

\newtheorem{rg}{Reguła}
\newtheorem{twr}{Twierdzenie}

\title{Proste algorytmy klasyfikacji tekstu \\ Założenia wstępne projektu}
\author{Marcin Kaczyński \and Krystian Lieber}

\begin{document}

\maketitle

\section{Opis zadania} 

W ramach zadania - ''Proste algorytmy klasyfikacji tekstu (TF-IDF, naiwny klasyfikator Bayesowski, kNN). Porównania ze standardowymi algorytmami klasyfikacji dostępnymi w R.'' zajmiemy się implementacją 3 wymienionych klasyfikatorów które zostaną dostosowane i wykorzystane w zagadnieniu rozpoznawania reklam i niechcianych wiadomości SMS.\\

Do nauki i oceny klasyfikatorów zostanie wykorzystany zbiór \textit{SMS Spam Collection}\footnote{http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection} z repozytorium UCI. Opis tego zbioru znajduje się w kolejnych sekcjach niniejszego dokumentu.

\section{Algorytmy}

Załóżmy, że mamy dany zbiór uczący podzielony na klasy $C_i, i = 1, 2, \dots, m$. W zadaniu $i=2$. 

\subsection{Algorytm \textit{k-NN}}

W algorytmie klasyfikacji \textit{k-NN} dla klasyfikowanego przykładu $x$ szukamy $k$ (wartość z góry ustalona) próbek które leżą najbliżej $x$ w sensie ustalonej miary a następnie na podstawie głosowania wśród wybranych sąsiadów określamy do której klasy $C_i$ należy $x$.\\

W zadaniu do znalezienia najbliższych sąsiadów zostanie wykorzystana \textit{miara kosinusowa}.

\begin{center}
$sim(v_1, v_2) = \frac{v_1*v_2}{|v_1||v_2|}$
\end{center}

oraz miara \textit{TF-IDF} (opisana w kolejnych sekcjach).\\

Aby móc porównywać słowa wg wspomnianych miar, należy je przedstawić w postaci wektorowej. Podstawowa idea reprezentacji wektorowej sprowadza się do tego, że wiadomość jest reprezentowana w postaci wektora częstości występowania słów. Zbiór wszystkich wiadomości można przedstawić w postaci macierzy, o nazwie \textit{Term Frequency Matrix}, której element $[w_i, s_i]$ reprezentuje liczbę wystąpień słowa $s_i$ w wiadomości $w_i$. Dowolna wiadomość $w_i$ jest reprezentowana w postaci wektora częstości występowania słów kluczowych.

\subsection{Algorytm \textit{TF-IDF}}

\paragraph{}

\textit{TF-IDF} (Term Frequency Inverted Document Frequency) jest metodą wyznaczania ważności słowa występującego w dokumencie w kontekście korpusu. Waga rośnie proporcjonalnie do ilości wystąpień w tekście, ale jest skalowana przez ilość wszystkich wystąpień. Takie podejście pozwala na eliminację słów często występujących, które jednocześnie nie niosą z sobą informacji. Takie skalowanie pozwala uniezależnić się od przygotowywanej listy tzw. \textit{stopwords}.

\paragraph{}
Główne założenia na których opiera się \textit{TF-IDF} to:

\begin{itemize}
 \item słowo występujące w każdym dokumencie jest mało interesujące
 \item słowo występujące tylko w kilku dokumentach jest bardziej interesujące
\end{itemize}

\paragraph{Obliczenia} 

\subparagraph{TF}
\begin{equation}
  tf(t,d)=f(t,d)  
\end{equation}

gdzie t - słowo,  
d - dokument

f(t,d) ilość wystąpień słowa t w dokumencie d

\subparagraph{IDF}
\begin{equation}
idf(t,D)=\log \frac{D}{d}
\end{equation}

gdzie t - słowo, D - liczba dokumentów, d - liczba dokumentów zawierających słowo t

\subparagraph{TF-IDF}
  
\begin{equation}
tfidf(t,d,D)=tf(t,d)*idf(t,D)
\end{equation}

\textit{TF-IDF} najczęściej jest wykorzystywane jako metoda obliczania wagi w innym algorytmie. Jednak można sobie wyobrazić metodę klasyfikacji polegającą na obliczeniu współczynnika tfidf dla słów z danej klasy w kontekście zbioru wszystkich dokumentów. Suma współczynników dla słów dokumentów była by wynikiem, który następnie byłby skalowany ilością słów w dokumencie. Ostateczna decyzja jest wynikiem wyboru tej klasy dla której
uzyskany wynik jest najwyższy.
  
\subsection{Naiwny klasyfikator Bayesa}
 
\begin{rg}[Bayes]
Próbkę $X$ klasyfikujemy jako pochodzącą z tej klasy $C_i$, dla której wartość $P(C_i|X), i = 1, 2, \dots, m$, jest największa.
\end{rg}
 
Problem sprowadza się do wyznaczenia prawdopodobieństw $P(C_i|X)$.
W ogólności aby wyznaczyć te prawdopodobieństwa, należy skorzystać z~następującego twierdzenia:

\begin{twr}[Bayes]
$P(C|X) = \frac{P(X|C)*P(C)}{P(X)}$
\end{twr}
 
gdzie:

\begin{itemize}
\item \textbf{$P(C)$} jest prawdopodobieństwem \textit{a priori} wystąpienia
klasy $C$,
\item \textbf{$P(X|C)$} oznacza prawdopodobieństwo \textit{a posteriori}, że
$X$ należy do klasy $C$,
\item \textbf{$P(X)$} oznacza prawdopodobieństwo \textit{a priori} wystąpienia przykładu $X$.
\end{itemize} 
 
Przy założeniu o niezależności atrybutów, prawdopodobieństwo $P(X|C_i)$ możemy wyznaczyć z formuły $P(X|C_i) = \prod\limits_{j=1}^n P(x_j|C_i)$, gdzie wartości prawdopodobieństw iloczynu estymujemy
w zależności od przyjętej metody.\\

Warto zaznaczyć, że w przypadku dokumentów tekstowych nie jest spełnione założenie o warunkowej niezależności wartości atrybutów, jednak w praktyce nie obniża to skuteczności klasyfikatora. W zadaniu klasyfikowania wiadomości atrybutami są kolejne słowa w wiadomości.\\

Przyjmujemy założenie, że prawdopodobieństwo wystąpienia słowa w tekście jest niezależne od jego pozycji. Dzięki temu założeniu znacząco maleje liczba estymat prawdopodobieństw które należy wyznaczyć podczas uczenia.\\

Do wyznaczenia wspomnianych estymat $P(x_j|C_i)$ wykorzystujemy następujący wzór:

\begin{center}
$\frac{n_k + 1}{n + |D|}$
\end{center}

gdzie $n$ - całkowita liczba słów w wiadomościach uczących które należą do klasy $C_i$, $n_k$ - liczba wystąpień słów $x_j$ w tekstach z klasy $C_i$, a $|D|$ - liczba rozróżnialnych słów występujących we wszystkich tekstach uczących.

\section{Plan eksperymentów}

\subsection{Pytania, na które będzie poszukiwana odpowiedź}

Celem zadania jest odpowiedzenie na pytanie, czy przekazana wiadomość SMS jest pożądaną, zwykłą wiadomością, czy zawiera niepożądane treści lub reklamy.

\subsection{Charakterystyka zbioru danych}

Wybrany zbiór danych (\textit{SMS Spam Collection}) jest zbiorem etykietowanych wiadomości które zostały zebrane na potrzeby badania spamu wysyłanego SMS'ami. Korpus składa się z $4827$ zwykłych wiadomości oraz z $747$ wiadomości zawierających spam. Cała kolekcja wiadomości jest umieszczona w jednym pliku, w którym każda linijka składa się z etykiety wiadomości którą poprzedza oraz z wiadomości w oryginalnej postaci. Poniżej kilka przykładów:

\begin{itemize}
	\item ham What you doing?how are you? 
	\item ham dun say so early hor... U c already then say... 
	\item ham MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H* 
	\item spam FreeMsg: Txt: CALL to No: 86888 \& claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop 
	\item spam Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B 
	\item spam URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU 
\end{itemize}

Wiadomości zostaną poddane wstępnemu przetwarzaniu w którym:

\begin{enumerate}
	\item Litery we wszystkich słowach zostaną zamienione na małe.
	\item Zostaną rozwinięte skróty pojawiające się w wiadomościach (lub usunięte jeżeli okaże się, że skróty znajdują się na liście \textit{stopwords}, co na razie pozostaje kwestią otwartą).
	\item Liczby i daty zostaną usunięte z tekstów.
\end{enumerate}

\subsection{Parametry algorytmów}

\paragraph{Algorytm kNN}

W algorytmie kNN będziemy porównywać wpływ liczby sąsiadów na otrzymywane wyniki, a dodatkowo sprawdzimy 2 miary obliczania odległości (\textit{miarę kosinusową} i \textit{miarę TF-IDF}).

\paragraph{Algorytm TF-IDF}

\paragraph{Naiwny klasyfikator Bayesa}

Dla naiwnego klasyfikatora Bayesa, poza wykonaniem obliczeń dla prawdopodobieństw \textit{a priori} wyboru klasy takich jak wynikają z charakterystyki zbioru uczącego, zbadamy jaki wpływ na wyniki będzie miało zmienienie tych wartości.

\subsection{Sposób oceny jakości modeli}

W przypadku klasyfikacji narzuca się prosty sposób oceny jakości modeli, taki, że dzielimy próbki na 2 podzbiory - zbiór uczący i zbiór testowy. Aby ocenić model przeprowadzamy uczenie klasyfikatora na próbkach pochodzących ze zbioru uczącego, a następnie sprawdzamy jaką jakość klasyfikacji uzyskujemy dla próbek ze zbioru testowego.\\

W naszym przypadku będziemy mierzyć jakość modeli na podstawie 2 wskaźników. Będziemy określali jakość klasyfikacji zwykłych wiadomości (a więc iloraz poprawnie sklasyfikowanych zwykłych wiadomości do wszystkich zwykłych wiadomości) oraz jakość klasyfikacji spamu (analogicznie iloraz poprawnie klasyfikowanych niechcianych wiadomości do ich łącznej liczby).\\

\section{Kwestie otwarte}

Ponieważ wykorzystywany korpus zawiera istotnie mniej spamu niż zwykłych wiadomości, aby zwiększyć jakość klasyfikacji i samą jakość oceny modelu tych drugich wiadomości skorzystamy z techniki nazywanej \textit{leave one out} lub \textit{jack knife}. Technika zakłada wielokrotne testowanie modelu przy takim podziale całego
zbioru próbek, że w zbiorze uczącym znajduje się $(n-1)$ próbek, a w zbiorze testowym 1 próbka. W naszym przypadku zmodyfikujemy tę technikę, tak żeby zbiór testowy składał się z pewnej liczby $k$ zwykłych wiadomości i 1 wiadomości zawierającej spam, a zbiór uczący ze wszystkich pozostałych próbek. Jeżeli uczenie klasyfikatorów okaże się czasochłonne, prawdopodobnie zrezygnujemy z tej części.\\

Otwartą kwestię stanowi dodatkowo zbiór \textit{stopwords} czyli słów które nie mają znaczenia dla klasyfikacji - te słowa mogą zostać usunięte z tekstów. Dodatkowo w przypadku wiadomości SMS warto zastanowić się nad pojawiającymi się w wiadomościach skrótami (być może skróty zostaną włączone do listy \textit{stopwords} lub rozwinięte do pełnych słów).

\section{Dodatek: Algorytmy dostępne w \textit{R}} 

Poniżej znajduje się lista algorytmów klasyfikacji zaimplementowanych w \textit{R}. W ramach badań porównamy wyniki uzyskane przez zimplementowane
przez nas algorytmy do wyników działania algorytmu \textit{SVM} i klasyfikacji na podstawie drzewa \textit{CART}.

  \begin{itemize}
  % \item grupa Boosting
  % \begin{itemize}
  	% \item AdaBoost - biblioteka ada.
  % \end{itemize}
  \item SVM (Support Vector Machine), dostępne w bibliotekach: e1071, kemlab, klaR, svmpath.
  \item kNN, dostępne w bibliotekach: knn, knntree, knnflex, kknn, RWeka.
  \item Naiwny klasyfikator Bayesa - biblioteka e1071.
  \item Classification and regression trees (CART), dostępne w bibliotekach: rpart, tree.
    % \begin{itemize}
  	% \item 
  	% \item J48 - RWeka
  % \end{itemize}
  \end{itemize}

\end{document}
