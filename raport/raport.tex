\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{fullpage}
\usepackage{hyperref}

\newtheorem{rg}{Reguła}
\newtheorem{twr}{Twierdzenie}

\title{Proste algorytmy klasyfikacji tekstu \\ Raport końcowy}
\author{Marcin Kaczyński \and Krystian Lieber}

\begin{document}

\maketitle

\section{Opis zadania} 

W ramach zadania - ''Proste algorytmy klasyfikacji tekstu (TF-IDF, naiwny klasyfikator Bayesowski, kNN). Porównania ze standardowymi algorytmami klasyfikacji dostępnymi w R.'' zaimplementowano 3 wymienione klasyfikatory które następnie zostały wykorzystane w zagadnieniu rozpoznawania reklam i niechcianych wiadomości SMS.\\

Do nauki i oceny klasyfikatorów wykorzystano zbiór \textit{SMS Spam Collection}\footnote{http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection} z repozytorium UCI. Opis zbioru znajduje się w sekcji \ref{dane:charakterystyka}.

\section{Algorytmy}

W sekcji znajduje się opis wykorzystywanych algorytmów. W stosunku do informacji zawartych w dokumentacji wstępnej, opis został rozszerzony o 
podstawowe informacje i decyzje związane z implementacją. Zgodnie z wymaganiami, algorytmy zostały zaimplementowane w języku \textbf{R}.\\

Ogólnie implementacja wszystkich algorytmów wykorzystuje funkcje dostępne w pakiecie \textit{tm}\footnote{http://cran.r-project.org/web/packages/tm/index.html}. W szczególności wykorzystywane są funkcje pozwalające na budowanie korpusu z tekstów (w tym przypadku wiadomości są traktowane jako dokumenty wchodzące w skład korpusu), oraz funkcje do wyznaczania częstości występowania słów w korpusie.

\subsection{Algorytm \textit{k-NN}}

opisz

\subsection{Naiwny klasyfikator Bayesa}

\begin{rg}[Bayes]
Próbkę $X$ klasyfikujemy jako pochodzącą z tej klasy $C_i$, dla której wartość $P(C_i|X), i = 1, 2, \dots, m$, jest największa.
\end{rg}
 
Problem sprowadza się do wyznaczenia prawdopodobieństw $P(C_i|X)$. W ogólności aby wyznaczyć te prawdopodobieństwa, należy skorzystać z~następującego twierdzenia:

\begin{twr}[Bayes]
$P(C|X) = \frac{P(X|C)*P(C)}{P(X)}$
\end{twr}
 
gdzie:

\begin{itemize}
\item \textbf{$P(C)$} jest prawdopodobieństwem \textit{a priori} wystąpienia klasy $C$,
\item \textbf{$P(X|C)$} oznacza prawdopodobieństwo \textit{a posteriori}, że $X$ należy do klasy $C$,
\item \textbf{$P(X)$} oznacza prawdopodobieństwo \textit{a priori} wystąpienia przykładu $X$.
\end{itemize} 
 
Przy założeniu o niezależności atrybutów, prawdopodobieństwo $P(X|C_i)$ możemy wyznaczyć z formuły $P(X|C_i) = \prod\limits_{j=1}^n P(x_j|C_i)$, gdzie wartości prawdopodobieństw iloczynu estymujemy wykorzystując następujący wzór:

\begin{center}
$\frac{n_k + 1}{n + |D|}$
\end{center}

gdzie $n$ - całkowita liczba słów w wiadomościach uczących które należą do klasy $C_i$, $n_k$ - liczba wystąpień słów $x_j$ w tekstach z klasy $C_i$, a $|D|$ - liczba rozróżnialnych słów występujących we wszystkich tekstach uczących.

Warto zaznaczyć, że w przypadku dokumentów tekstowych nie jest spełnione założenie o warunkowej niezależności wartości atrybutów (w tekstach wystąpienie niektórych słów może zależeć od innych, zdania mają pewną uporządkowaną strukturę), jednak w praktyce nie obniża to skuteczności klasyfikatora. W zadaniu klasyfikowania wiadomości atrybutami są kolejne słowa w wiadomości.\\



\subsection{Algorytm \textit{TF-IDF}}

mk opisze


\subsection{Algortym z R}

myślę, że bez szczegółów, tylko stwierdzenie co, z jakiego pakietu + referencja do opisu

\subsection{Algorytm II z R}

\section{Opis eksperymentów}

\subsection{Pytania, na które poszukiwano odpowiedzi}

Celem zadania było odpowiedzenie na pytanie, czy przekazana wiadomość SMS jest pożądaną, zwykłą wiadomością, czy zawiera niepożądane treści lub reklamy.

\subsection{Charakterystyka zbioru danych}\label{dane:charakterystyka}

Wybrany zbiór danych (\textit{SMS Spam Collection}) jest zbiorem etykietowanych wiadomości które zostały zebrane na potrzeby badania spamu wysyłanego SMS'ami. Korpus składa się z $4827$ zwykłych wiadomości oraz z $747$ wiadomości zawierających spam. Cała kolekcja wiadomości jest umieszczona w jednym pliku, w którym każda linijka składa się z etykiety wiadomości którą poprzedza oraz z wiadomości w oryginalnej postaci. Poniżej kilka przykładów:

\begin{itemize}
	\item ham What you doing?how are you? 
	\item ham dun say so early hor... U c already then say... 
	\item ham MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H* 
	\item spam FreeMsg: Txt: CALL to No: 86888 \& claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop 
	\item spam Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B 
	\item spam URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU 
\end{itemize}

\subsection{Preprocessing zbioru danych}

W ramach wstępnego przetwarzania danych, zostały wykonana następujące kroki:

\begin{itemize}
\item z tekstów zostały wycięte znaki interpunkcyjne i znaki specjalne,
% \# \& \' \( \) \* \+ \, \- \. \/ \: \; \< \= \> \? \@ \[ \\ \] \^ \_ \` \{ \| \} \~ \% \$ \- \! \"
\item z tekstów zostały wycięte wszystkie liczby,
\item wielokrotnie występujące białe znaki zostały zastąpione pojedynczymi spacjami,
\item zostały usunięte słowa z listy stopwords dla języka angielskiego zdefiniowanej w pakiecie \textit{tm} R.
\end{itemize}

Implementacja przewiduje również usunięcie znaczników xml z tekstów, ale w przypadku badanego zbioru nie występuje potrzeba usuwania takich znaczników. W stosunku do wcześniejszch rozważań, nie wykonano rozwijania skrótów pojawiających się w wiadomościach, ani nie włączono ich do listy stopwords.

\subsection{Parametry algorytmów} % parametry algorytmów, których wpływ na wyniki był badany,

\subsubsection{Ogrniczenie słów w zbiorze uczącym}

Ogólnie w tekstach w językach naturalnych, często pojawiają się słowa które wydają się nie mieć wpływu na to jak można sklasyfikować dany dokument. Wśród tych słów znajdują się np. zaimki, albo spójniki, które ze względu na swój charakter często są włączane do listy stopwords, jako nie mające wpływu na znaczenie dokumentu. Analogicznie, można oczekiwać, że słowa które bardzo rzadko pojawiają się w tekstach, również mogą nie mieć wpływu
na ogólne znaczenie. Opierając się na tej przesłance, dodano parametr który opisuje minimalną częstość wystąpienia słowa w korpusie. Słowa, które
występują w korpusie mniej razy, niż określa parametr, zostają usunięte. Wydaje się, że występowanie takich słów, jest nieporządane, a ich usunięcie
poza poprawą jakości klasyfikacji przynosi również zysk w postaci zmniejszenia wymagań pamięciowych i czasowych algorytmów.\\

Zakładamy, że taki parametr pozwoli m.in. na usunięcie nazw własnych, które wydają się pojawiać niezależnie od tego czy wiadomość należy sklasyfikować jako spam, czy jako zwykłą, porządaną wiadomość. 

\subsubsection{Algorytm \textit{k-NN}}

opisz

\subsubsection{Algorytm \textit{TF-IDF}}

Skalowanie wartości miary TF-IDF w pewnym sensie powoduje usunięcie informacji o wadze danego słowa w ramach klasy, a z drugiej strony brak takiego skalowania bardzo może wprowadzać błędy dla zbiorów o nierównomiernym rozkładzie próbek (tak jest w przypadku zbioru \textit{SMSSpamCollection}. W ramach eksperymentów wprowadzono do algorytmu dodatkowy modyfikator związany z prawdopodobieństwem wystąpienia danej klasy - w dodatkowym wariancie algortymu suma wag \textit{tf-idf} dla wiadomości jest mnożona przez prawdopodobieństwo wystąpienia danej klasy. 

\subsubsection{Naiwny klasyfikator Bayesa}

W ramach eksperymentów z klasyfikatorem Bayesa, zbadano jaki wpływ ma zmiana prawdopodobieństwa wystąpienia słowa w klasie. Zostały zbadane następujące warianty:

\begin{itemize}
\item prawdopobieństwo klasy wynika z liczności próbek z tej klasy w zbiorze uczącym, 
\item prawdopodobieństwa wszystkich klas są równoprawdopodobne,
\item prawdopodobieństwo wystąpienia klasy \textit{spam}, jest wyższe niż wynika z liczności próbek z tej klasy.
\end{itemize}

\subsection{Ocena jakości modeli} % sposób oceny jakości modeli,

Modele dla opisanych algorytmów były budowane z wykorzystaniem $70\%$ danych ze zbioru \textit{SMSSpamCollection}. Dane do budowy modeli zostały
wybrane w sposób losowy, z zachowaniem proporcji w klasach (tzn. wybierano dokładnie $70\%$ danych przypisanych do klasy \textit{spam} i $70\%$ 
danych z klasy \textit{ham}. Pozostałe $30\%$ wykorzystano do przetestowania jakości budowanych modeli. Algorytmy były testowane z wykorzystaniem
tych samych zbiorów danych uczących i testowych, w celu zachowania możliwie dużego stopnia obiektywności oceny.\\

Modele były oceniane w taki sposób, że dla każdej próbki ze zbioru testowego, porównywano rzeczywistą klasę do której przypisana jest próbka, z
wartością zwracaną przez algorytm. W ramach oceny uwzględniono oddzielnie jakość oceny klasyfikacji próbek ze zbioru \textit{spam} (iloraz niechcianych widomości do ich łącznej liczny) oraz \textit{ham} (analogicznie), oraz ogólny wskaźnik jakości (iloraz prawidłowo sklasyfikowanych próbek do wszystkich próbek w zbiorze testowym).

\section{Wyniki}

W tabelach w poniższych sekcjach, przyjęto następującą konwencję:\\

\begin{itemize}
\item min: $k$ - oznacza, że z korpusu usunięto słowa o liczności mniejszej niż $k$,
\item wartości w komórkach oznaczają jakość klasyfikacji obliczoną jako iloraz próbek dobrze sklasyfikowanych do wielkości całego zbioru.
\end{itemize}

Dla przykładowego zbioru testowego, w którego skład wchodzi $70\%$ zbioru \textit{SMSSpamCollection},
rozmiar korpusu przedstawia się następująco:\\

\begin{tabular}{l | l}
0 & 6313 pojęć \\
1 & 2998 pojęć \\
2 & 2045 pojęć \\
3 & 1588 pojęć \\
4 & 1310 pojęć \\
5 & 1122 pojęcia \\
6 & 973 pojęcia \\
7 & 866 pojęć \\
10  & 665 pojęć \\
30  & 237 pojęć \\
100 & 57 pojęć \\
\end{tabular}
\\

gdzie wartość z pierwszej kolumny, oznacza, że słowa występujące w korpusie mniej razy, niż ta wartość, zostały usunięte.

\subsubsection{Algorytm \textit{k-NN}}

opisz

\subsubsection{Algorytm \textit{TF-IDF}}

\subsubsection{Naiwny klasyfikator Bayesa}

\begin{itemize}
\item Wersja 1. Prawdopodobieństwo wystąpienia klasy jest takie jak wynika z liczności próbek danej klasy, a więc w przypadku zbioru 
	\textit{SMSSpamCollection} $0.866$ dla klasy \textit{ham} i $0.134$ dla klasy \textit{spam}.
\item Wersja 2. Prawdopodobieństwa wystąpienia klas są równe.
\item Wersja 3. Prawdopodobieństwo wystąpienia klasy \textit{ham} jest większe niż w punkcie~1.
\end{itemize}

\vspace{0.5cm}

\begin{table}
\centering
\begin{tabular}{|l||p{2.5cm}|p{2.5cm}||p{2.5cm}|}
\hline
liczność & \textit{ham} & \textit{spam} & ogółem \\ \hline
min: $0$ & 0.9883 & 0.8889 & 0.9749 \\ \hline
min: $1$ & 0.9855 & 0.9111 & 0.9755 \\ \hline
min: $2$ & 0.9862 & 0.9244 & 0.9778 \\ \hline
min: $3$ & 0.9869 & 0.9244 & 0.9785 \\ \hline
min: $4$ & 0.9883 & 0.9244 & 0.9790 \\ \hline
min: $5$ & 0.9890 & 0.9289 & 0.9803 \\ \hline
min: $6$ & 0.9890 & 0.9244 & 0.9803 \\ \hline
min: $7$ & 0.9862 & 0.9244 & 0.9779 \\ \hline
min: $10$ & 0.9848 & 0.9244 & 0.9767 \\ \hline
min: $30$ & 0.9772 & 0.8533 & 0.9642 \\ \hline
min: $100$ & 0.7289 & 0.9862 & \\ \hline

\end{tabular}
\caption{Bayes - wersja 1}
\end{table}

\begin{table}
\centering
\begin{tabular}{|l||p{2.5cm}|p{2.5cm}||p{2.5cm}|}
\hline
liczność & \textit{ham} & \textit{spam} & ogółem \\ 
\hline

min: $0$ & 0.9745 & 0.9200 & 0.9671 \\ \hline
min: $5$ & 0.9648 & 0.9333 & 0.9606 \\ \hline

\end{tabular}
\caption{Bayes - wersja 2}
\end{table}

W przypadku tabeli\ref{bayes:tab3} w kolumnie 2 zamieszczono informację o ustalonym prawdopodobieństwie
wystąpienia klasy \textit{spam}. Jej rzeczywiste prawdopodobieństwo to $0.134$.

\begin{table}
\centering
\begin{tabular}{|l|l||p{2.5cm}|p{2.5cm}||p{2.5cm}|}
\hline
liczność &  & \textit{ham} & \textit{spam} & ogółem \\ 
\hline

min: $0$ & 0.2 & 0.9862 & 0.9022 & 0.9749 \\ \hline
min: $5$ & 0.2 & 0.9841 & 0.9333 & 0.9773 \\ \hline
min: $0$ & 0.3 & 0.9821 & 0.9200 & 0.9737 \\ \hline
min: $5$ & 0.3 & 0.9786 & 0.9333 & 0.9725 \\ \hline

\end{tabular}
\caption{Bayes - wersja 3}
\label{bayes:tab3}
\end{table}

\section{Wnioski}

jak masz wnioski to wklejaj, a jak nie to coś tu naściemniam

\end{document}
